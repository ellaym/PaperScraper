# Project Architecture Overview

## Introduction

The PaperScraper project automates the process of scraping, downloading, summarizing new research papers and notifying the results to the user by email.

## Components

### 1. **Scraper Module**
- **Function**: : Fetches new papers from various sources like arXiv using APIs. It periodically queries the sources for new papers based on predefined criteria.
- **Technologies**: Python, `arxiv` library.

### 2. **Extraction Pipeline**
- **Function**: Extracts text from PDFs and generates a ChatGPT query. Initially, it queries only the abstract of the paper to determine relevance. If the abstract is relevant, it generates a new ChatGPT query for the entire content of the paper.
- **Technologies**: Python, `PyPDF2`, `requests`

### 3. **GPT Module**
- **Function**: REST API server that receives a query and communicates with the OpenAI GPT API. It processes the query and returns a response generated by GPT.
- **Technologies**: Python, `Flask`, OpenAI GPT API.

### 4. **Mailing Module**
- **Function**: REST API server that receives the summarized data and emails it to a configured address. This module handles email sending and scheduling tasks if required.
- **Technologies**: Python, `Flask`, `smtplib`.

## Data Flow

1. **User Initiates Scraping:**
- The system can be triggered manually or automatically (e.g., via a scheduler).
- The Scraper Module queries sources like arXiv using APIs to fetch new papers matching the specified criteria (e.g., cryptography and algorithmic research) and saves them into an output directory.

2. **Scraper Module Outputs Paper Metadata:**
- The Scraper Module collects metadata such as the title, abstract, authors, and content of the new paper. It passes this data to the Extraction Pipeline (with path to the file included).

3. **Extraction Pipeline Processes the Abstract:**
- The pipeline uses the abstract to form a query for the GPT Module.
- If the abstract is deemed relevant (based on predefined criteria), the pipeline proceeds to extract the entire paper from the file path.

4. **Extraction Pipeline Queries GPT for the Abstract:**
- The Extraction Pipeline sends a query containing the abstract to the GPT Module via the REST API.

5. **GPT Module Checks Relevance:**
- The GPT Module processes the query and sends it to the OpenAI GPT API.
- The GPT Module returns the result to the Extraction pipeline.

6. **Extraction Pipeline Extracts the data:**
-  If the abstract is deemed relevant, the pipeline proceeds to extract the entire paper from the file path.

7. **Extraction Pipeline Queries GPT for data:**
- The Extraction Pipeline sends a query containing the full paper to the GPT Module via the REST API.

8. **GPT Module Generates Summary:**
- The GPT Module processes the query and sends it to the OpenAI GPT API.
- The GPT Module returns the result to the Extraction pipeline.

9. **Extraction Pipeline Outputs the Summary:**
- The Extraction Pipeline receives the summary from the GPT Module and prepares it for further processing, such as sending the summarized content via email.

10. **Mailing Module Sends Summary:**
- The Mailing Module is triggered to send the summarized paper via email to the configured recipient.
- The Mailing Module uses the provided email address and sends the summary using smtplib.

## Technologies Stack

- **Backend**: Python, Flask, requests, smtplib
- **APIs**: arXiv API, OpenAI GPT API
- **Version Control**: Git, GitHub
